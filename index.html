<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<!-- saved from url=(0036)https://www.cs.ubc.ca/labs/lci/cvrg/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<title>Probabilistic ML Reading Group</title>
		<!-- Put meta information here. -->
		
		<!-- <link rel="stylesheet" href="../ubc_clf/ubc_css/main.css"> -->

		<!-- BOOTSTRAP -->
		<!-- Latest compiled and minified CSS -->
		<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

		<!-- Optional theme -->
		<!-- <link rel="stylesheet" href="https://bootswatch.com/readable/bootstrap.min.css"> -->
		<link rel="stylesheet" href="https://bootswatch.com/yeti/bootstrap.min.css">

		<!-- Latest compiled and minified JavaScript -->
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>

		<!--
	  <link rel="stylesheet" href="main.css">
		-->
	</head>
	<!-- Body of page. -->
	<body data-new-gr-c-s-check-loaded="14.1016.0" data-gr-ext-installed="">
		<div class="container">
			<div class="jumbotron">
				<h1>Probabilistic ML Reading Group</h1>

				<!--p>CVRG meets on <strong>Wednesdays at 4:00 pm</strong> (for Jan - Apr, 2020) in <strong>ICCS X836</strong>.</p-->

				<!--<p>To <strong>subscribe</strong> to the mailing list for talk announcements, send a message to <a href="mailto:majordomo@cs.ubc.ca">majordomo@cs.ubc.ca</a> with the words <code>subscribe cvrg-l</code> in the body.</p>

				<p>A list of upcoming papers can be found <a href="https://www.cs.ubc.ca/labs/lci/cvrg/#upcoming">below</a>. To be added to the schedule contact <strong>Shih-Han</strong> (<a href="mailto:shchou75@cs.ubc.ca">shchou75@cs.ubc.ca</a>).</p>-->
			</div>

			<div class="row">
				<div class="col-md-12">
					<a name="upcoming"></a>
					<h1>Upcoming presentations</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
								<th>Other References (if any)</th>
							</tr>
						</thead>

						<tbody>

                                 <tr>
                                 </tr>
								 
								 <tr>

									<!--
                                   <td> Apr. 6 </td>
                                   <td> <br> Shih-Han </td>
                                   <td> <b> Multi-modality </b> <br> VisualCOMET: Reasoning about the Dynamic Context of a Still Image [<a href="https://arxiv.org/pdf/2004.10796.pdf">link</a>] </td>
								   <td></td>
									-->
                                   
								   <!-- 
									<td> <br> Shih-Han <br> <br> Serge </td>
                                   <td> <b> Multi-modality </b> <br> VisualCOMET: Reasoning about the Dynamic Context of a Still Image [<a href="https://arxiv.org/pdf/2004.10796.pdf">link</a>] <br> <b> Object Detection </b><br> Sparse R-CNN: End-to-End Object Detection with Learnable Proposals [<a href="https://arxiv.org/pdf/2011.12450.pdf">link</a>] </td> 
									-->

                                 </tr>


                                                     <!--tr>
                                                       <td> Mar. 25 </td>
                                                       <td> <br> Ariel <br> Colin </td>
                                                       <td> <b> Learning </b> <br> Compositional generalization through meta sequence-to-sequence learning [<a href="https://arxiv.org/pdf/1906.05381.pdf">link</a>] <br> Visual Concept-Metaconcept Learning [<a href="http://papers.nips.cc/paper/8745-visual-concept-metaconcept-learning">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Apr. 1 </td>
                                                       <td> <br> Lixin <br> Lai </td>
                                                       <td> <b> Learning </b> <br> Active Generative Adversarial Network for Image Classification [<a href="https://arxiv.org/pdf/1906.07133.pdf">link</a>] <br> GNNExplainer: Generating Explanations for Graph Neural Networks [<a href="https://arxiv.org/pdf/1903.03894.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Apr. 8 </td>
                                                       <td> <br> Siddhesh <br> Suhail </td>
                                                       <td> <b> Learning </b> <br> Deep Set Prediction Networks [<a href="https://papers.nips.cc/paper/8584-deep-set-prediction-networks.pdf">link</a>] <br> Practical Lossless Compression with Latent Variables using Bits Back Coding [<a href="https://arxiv.org/pdf/1901.04866.pdf">link</a>] </td>
                                                     </tr-->

						</tbody>

					</table>

					<h1>Finished presentations, 2021</h1>
                                        <table class="table table-striped table-condensed table-hover">
                                                <thead>
                                                        <tr>
                                                                <th class="col-md-2">Date</th>
                                                                <th class="col-md-2">Presenter</th>
                                                                <th>Paper or topic</th>
																<th>Other References (if any)</th>
                                                        </tr>
                                                </thead>

                                                <tbody>
                                                
												<tr>
													<td> July 1 </td>
													<td> <br> Aishwarya Gupta <br> Shilpa Chatterjee </td>
													<td> <b> Federated Learning </b> <br> Data-Free Knowledge Distillation for Heterogeneous Federated Learning - ICML 2021 [<a href="https://arxiv.org/pdf/2105.10056.pdf">link</a>] <br> <b> Active Learning </b> <br> Variational Adversarial Active Learning - ICCV 2019 [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Sinha_Variational_Adversarial_Active_Learning_ICCV_2019_paper.pdf">link</a>]</td>
												</tr>
												<tr>
                                                   <td> June 24 </td>
                                                   <td> <br> Dhanajit Brahma <br> Kushagra Pandey </td>
                                                   <td> <b> Federated Learning </b> <br> Communication-Efficient Learning of Deep Networks from Decentralized Data - AISTATS 2017 [<a href="http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf">link</a>] <br> Federated Learning via Posterior Averaging: A New Perspective and Practical Algorithms - ICLR 2021  [<a href="https://openreview.net/forum?id=GFsU8a0sGB">link</a>]</td>
                                                 </tr>
												 
                                                 
												<!--
                                                 <tr>
                                                   <td> Mar. 9 </td>
                                                   <td> <br> Yuhe <br><br> Rayat </td>
                                                   <td> <b> Segmentation </b> <br> ACFNet: Attentional Class Feature Network for Semantic Segmentation [<a href="https://arxiv.org/pdf/1909.09408.pdf">link</a>] <br><b> Object Detection </b> <br> Deformable DETR: Deformable Transformers for End-to-End Object Detection [<a href="https://arxiv.org/pdf/2010.04159.pdf">link</a>] </td>
                                                 </tr>

                                                 <tr>
                                                   <td> Mar. 2 </td>
                                                   <td> <br> Eric <br></td>
                                                   <td> <b> Attention </b> <br> Rethinking Attention with Performers [<a href="https://arxiv.org/pdf/2009.14794.pdf">link</a>]</td>
                                                 </tr>

                                                 <tr>
                                                   <td> Feb. 23 </td>
                                                   <td> <br> Siddhesh <br> <br> Tanzila <br> </td>
                                                   <td> <b> Graph Neural Network </b> <br> Temporal Graph Networks for Deep Learning on Dynamic Graphs [<a href="https://arxiv.org/pdf/2006.10637.pdf">link</a>] <br> <b> Multi-modality </b> <br> Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets [<a href="https://arxiv.org/pdf/2007.06877.pdf">link</a>] </td>
                                                 </tr>

                                                 <tr>
                                                   <td> Feb. 9 </td>
                                                   <td> <br> Muchen </td>
                                                   <td> <b> Graph Neural Network </b> <br> Graph-based global reasoning networks [<a href="https://arxiv.org/pdf/1811.12814.pdf">link</a>] </td>
                                                 </tr>

                                                 <tr>
                                                   <td> Feb. 2 </td>
                                                   <td> <br> Raghav <br> </td>
                                                   <td> <b> Video </b> <br> Temporal Action Detection with Multi-level Supervision [<a href="https://arxiv.org/pdf/2011.11893.pdf">link</a>] </td>
                                                 </tr>

                                                 <tr>
                                                   <td> Jan. 26 </td>
                                                   <td> <br> Dryden <br> </td>
                                                   <td> <b> Learning </b> <br> Learning Representations that Support Extrapolation [<a href="https://arxiv.org/pdf/2007.05059.pdf">link</a>] </td>
                                                 </tr>
												-->

                        </tbody>
                    </table>


					<!--
					<h1>Finished presentations, 2020</h1>
                                        <table class="table table-striped table-condensed table-hover">
                                                <thead>
                                                        <tr>
                                                                <th class="col-md-2">Date</th>
                                                                <th class="col-md-2">Presenter</th>
                                                                <th>Paper or topic</th>
                                                        </tr>
                                                </thead>

                                                <tbody>

                                                     <tr>
                                                       <td> Dec. 18 </td>
                                                       <td> <br> Neil <br> <br> Ariel </td>
                                                       <td> <b> 3D Vision </b> <br> Self-Calibration Supported Robust Projective Structure-from-Motion [<a href="https://arxiv.org/pdf/2007.02045.pdf">link</a>] <br> <b> Learning </b> <br> Demystifying Contrastive Self-Supervised Learning: Invariances, Augmentations and Dataset Biases [<a href="https://arxiv.org/pdf/2007.13916.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Dec. 11 </td>
                                                       <td> <br> Daniel Rebain <br> Wei Jiang </td>
                                                       <td> <b> 3D Vision </b> <br> NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections [<a href="https://arxiv.org/pdf/2008.02268.pdf">link</a>] <br> Crowdsampling the Plenoptic Function [<a href="https://arxiv.org/pdf/2007.15194.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Dec. 4 </td>
                                                       <td> <br> Shih-Yang <br> Bicheng </td>
                                                       <td> <b> 3D Representation Learning </b> <br> Leveraging 2D Data to Learn Textured 3D Mesh Generation [<a href="https://arxiv.org/pdf/2004.04180.pdf">link</a>] <br> Object-Centric Multi-View Aggregation [<a href="https://arxiv.org/pdf/2007.10300.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Nov. 27 </td>
                                                       <td> <br> Xingzhe <br> Weiwei </td>
                                                       <td> <b> 3D Representation Learning </b> <br> PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding [<a href="https://arxiv.org/pdf/2007.10985.pdf">link</a>] <br> SoftPoolNet: Shape Descriptor for Point Cloud Completion and Classification [<a href="https://arxiv.org/pdf/2008.07358.pdf">link</a>] </td>
                                                     </tr>

                                                       <tr><td> Nov. 20 </td>
                                                       <td> <br> Raghav </td>
                                                       <td> <b> Video </b> <br> We Have So Much In Common: Modeling Semantic Relational Set Abstractions in Videos [<a href="https://arxiv.org/pdf/2008.05596.pdf">link</a>] </td>
                                                     </tr>
                                    
                                                     <tr>
                                                       <td> Oct. 30 </td>
                                                       <td> <br> Rayat <br> Suhail </td>
                                                       <td> <b> Graph Neural Network </b> <br> Dynamic Graph Message Passing Networks [<a href="https://arxiv.org/pdf/1908.06955.pdf">link</a>] <br> GPS-Net: Graph Property Sensing Network for Scene Graph Generation [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Lin_GPS-Net_Graph_Property_Sensing_Network_for_Scene_Graph_Generation_CVPR_2020_paper.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Oct. 23 </td>
                                                       <td> <br> Siddhesh <br> Yuhe </td>
                                                       <td> <b> Object Detection </b> <br> Frustratingly Simple Few-Shot Object Detection [<a href="https://arxiv.org/pdf/2003.06957.pdf">link</a>] <br> End-to-End Object Detection with Transformers [<a href="https://arxiv.org/pdf/2005.12872.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Oct. 16 </td>
                                                       <td> <br> Gabriel <br> Frank </td>
                                                       <td> <b> Generative Model Applications </b> <br> Semantic Pyramid for Image Generation [<a href="https://arxiv.org/pdf/2003.06221.pdf">link</a>] <br> GeLaTO: Generative Latent Textured Objects [<a href="https://arxiv.org/pdf/2008.04852v1.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Oct. 9 </td>
                                                       <td> <br> Tim <br> <br> Eric </td>
                                                       <td> <b> 3D Vision </b> <br> Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains [<a href="https://arxiv.org/pdf/2006.10739.pdf">link</a>] <br> <b> Human Pose </b> <br> Long-term Human Motion Prediction with Scene Context [<a href="https://arxiv.org/pdf/2007.03672.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Oct. 2 </td>
                                                       <td> <br> Tanzila <br> Abi </td>
                                                       <td> <b> Vision &amp; Sound </b> <br> Music Gesture for Visual Sound Separation [<a href="https://arxiv.org/pdf/2004.09476.pdf">link</a>] <br> Telling Left from Right: Learning Spatial Correspondence of Sight and Sound [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Telling_Left_From_Right_Learning_Spatial_Correspondence_of_Sight_and_CVPR_2020_paper.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Sep. 25 </td>
                                                       <td> <br> Mohammad <br> </td>
                                                       <td> <b> Segmentation </b> <br> PointRend: Image Segmentation as Rendering [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Kirillov_PointRend_Image_Segmentation_As_Rendering_CVPR_2020_paper.pdf">link</a>] <br> </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Mar. 11 </td>
                                                       <td> <br> Weidong <br> Yuan </td>
                                                       <td> <b> GAN &amp; 3D </b> <br> Semantic Image Synthesis with Spatially-Adaptive Normalization [<a href="https://arxiv.org/pdf/1903.07291.pdf">link</a>] <br> Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations [<a href="https://arxiv.org/pdf/1906.01618.pdf">link</a>] </td>                                                                                                                                                                                                                                       </tr>  
						     
						     <tr>
                                                       <td> Feb. 12 </td>
                                                       <td> <br> Tanzila <br> Yuchi </td>
                                                       <td> <b> Multimodality Applications </b> <br> Listen to Look: Action Recognition by Previewing Audio [<a href="https://arxiv.org/pdf/1912.04487.pdf">link</a>] <br> Language2Pose: Natural Language Grounded Pose Forecasting [<a href="https://arxiv.org/pdf/1907.01108.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Feb. 5 </td>
                                                       <td> <br> Raghav </td>
                                                       <td> <b> Video Action Recognition </b> <br> Action Genome: Actions as Composition of Spatio-temporal Scene Graphs [<a href="https://arxiv.org/pdf/1912.06992.pdf">link</a>] </td>
                                                     </tr>
							
						     <tr>
                                                       <td> Jan. 29 </td>
                                                       <td> <br> Farnoosh </td>
                                                       <td> <b> Vision &amp; Language </b> <br> Adaptively Aligned Image Captioning via Adaptive Attention Time [<a href="http://papers.nips.cc/paper/9096-adaptively-aligned-image-captioning-via-adaptive-attention-time">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Jan. 22 </td>
                                                       <td> <br> Shih-Han <br> Bicheng </td>
                                                       <td> <b> Vision &amp; Language </b> <br> Heterogeneous Graph Learning for Visual Commonsense Reasoning [<a href="https://arxiv.org/pdf/1910.11475.pdf">link</a>] <br> Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries [<a href="http://papers.nips.cc/paper/8533-drill-down-interactive-retrieval-of-complex-scenes-using-natural-language-queries">link</a>] </td>
                                                     </tr>

						</tbody>
					</table>
					-->

					<!--
					<h1>Finished presentations, 2019</h1>
                                        <table class="table table-striped table-condensed table-hover">
                                                <thead>
                                                        <tr>
                                                                <th class="col-md-2">Date</th>
                                                                <th class="col-md-2">Presenter</th>
                                                                <th>Paper or topic</th>
                                                        </tr>
                                                </thead>

                                                <tbody>
						     	
						     <tr>
                                                       <td> Dec. 5 </td>
                                                       <td> Polina <br> <br> Mark </td>
                                                       <td> Multi-Object Representation Learning with Iterative Variational Inference [<a href="https://arxiv.org/pdf/1903.00450.pdf">link</a>] <br> <b> Generative Model Applications </b> <br> Lifelong GAN: Continual Learning for Conditional Image Generation [<a href="https://arxiv.org/pdf/1907.10107.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Nov. 29 </td>
                                                       <td> <br> Tanzila <br> Alex </td>
                                                       <td> <b> Learning </b> <br> Invertible Residual Networks [<a href="https://arxiv.org/abs/1811.00995">link</a>] <br> Non-local Neural Network [<a href="https://arxiv.org/abs/1711.07971">link</a>] </td>
                                                     </tr>
						     
						     <tr>
                                                       <td> Nov. 21 </td>
                                                       <td> <br> Ariel <br> Rayat </td>
                                                       <td> <b> Reinforcement Learning / Learning </b> <br> Learning to Paint With Model-based Deep Reinforcement Learning [<a href="https://arxiv.org/abs/1903.04411v3">link</a>] <br> Deep Equilibrium Models [<a href="https://arxiv.org/abs/1909.01377">link</a>] </td>
                                                     </tr>
						     
					             <tr>
                                                       <td> Oct. 24 </td>
                                                       <td> <br> Yuchi <br> <br> Yuan </td>
                                                       <td> <b> 3D Human Pose </b> <br> 3D Human Pose Estimation in Video with Temporal Convolutions and Semi-supervised Training [<a href="https://arxiv.org/abs/1811.11742">link</a>] <br> <b> Generative Model Applications </b> <br> Neural Re-Simulation for Generating Bounces in Single Images [<a href="http://geometry.cs.ucl.ac.uk/projects/2019/bounce-neural-resim/">link</a>] </td>
                                                     </tr>
						     
						     <tr>
                                                       <td> Oct. 17 </td>
                                                       <td> <br> Alex <br> Setareh </td>
                                                       <td> <b> Graph Neural Network </b> <br> Modeling Relational Data with Graph Convolutional Networks [<a href="https://arxiv.org/abs/1703.06103">link</a>] <br> Understanding Attention and Generalization in Graph Neural Networks [<a href="https://arxiv.org/abs/1905.02850">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Oct. 10 </td>
                                                       <td> <br> Shih-Han <br> Peyman </td>
                                                       <td> <b> Vision &amp; Language </b> <br> From Recognition to Cognition: Visual Commonsense Reasoning [<a href="https://arxiv.org/pdf/1811.10830.pdf">link</a>] <br> Task-Driven Modular Networks for Zero-Shot Compositional Learning [<a href="https://arxiv.org/pdf/1905.05908.pdf">link</a>] </td>
                                                     </tr>

                                                     <tr>
                                                       <td> Oct. 3 </td>
                                                       <td> <br> Bicheng <br> Raghav </td>
                                                       <td> <b> Vision &amp; Language </b> <br> ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks [<a href="https://arxiv.org/abs/1908.02265">link</a>] <br> Video Representation Learning by Dense Predictive Coding [<a href="https://arxiv.org/pdf/1909.04656.pdf">link</a>] </td>
                                                     </tr>
  
						     <tr>
                                                       <td> Sep. 26 </td>
                                                       <td> <br> Ariel <br> Yuan </td>
                                                       <td> <b> Vision &amp; Graphics </b> <br> Fashion++: Minimal Edits for Outfit Improvement [<a href="https://arxiv.org/abs/1904.09261">link</a>] <br> PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization [<a href="https://arxiv.org/abs/1905.05172">link</a>] </td>
                                                     </tr>

						      <tr>
                                                       <td> Sep. 19 </td>
                                                       <td> <br> Siddhesh <br> Suhail </td>
                                                       <td> <b> Flow-based Generative Models </b> <br> Graph Normalizing Flows [<a href="https://arxiv.org/abs/1905.13177">link</a>] <br> Glow: Generative Flow with Invertible 1x1 Convolutions [<a href="https://arxiv.org/abs/1807.03039">link</a>] </td>
                                                      </tr>

						      <tr>
                                                       <td> Apr. 16 </td>
                                                       <td> <br> Bo <br> <br> Ariel </td>
                                                       <td> <b> GAN </b> <br> GAN Dissection: Visualizing and Understanding Generative Adversarial Networks [<a href="https://arxiv.org/pdf/1811.10597.pdf">link</a>] <br> <b> Unsupervised Learning </b> <br> Unsupervised Learning via Meta-Learning [<a href="https://openreview.net/pdf?id=r1My6sR9tX">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Apr. 9 </td>
                                                       <td> <br> Bicheng </td>
                                                       <td> <b> GAN </b> <br> A Style-Based Generator Architecture for Generative Adversarial Networks [<a href="https://arxiv.org/pdf/1812.04948.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Apr. 2 </td>
                                                       <td> <br> Lai <br> <br> Yuan </td>
                                                       <td> <b> Learning </b> <br> An Overview of Multi-Task Learning in Deep Neural Networks [<a href="https://arxiv.org/pdf/1706.05098.pdf">link</a>] <br> <b> Other </b> <br> Panoptic Feature Pyramid Networks [<a href="https://arxiv.org/pdf/1901.02446.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Mar. 26 </td>
                                                       <td> <br> Tanzila <br> <br> Lixin </td>
                                                       <td> <b> Lifetime Learning </b> <br> Efficient Lifelong Learning with A-GEM [<a href="https://arxiv.org/pdf/1812.00420.pdf">link</a>] <br> <b> Learning </b> <br> Curriculum Learning by Transfer Learning: Theory and Experiments with Deep Networks [<a href="https://arxiv.org/pdf/1802.03796.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Mar. 12 </td>
                                                       <td> <br> Polina <br> Rayat </td>
                                                       <td> <b> Lifetime Learning </b> <br> End-to-End Incremental Learning [<a href="https://arxiv.org/pdf/1807.09536.pdf">link</a>] <br> Memory Aware Synapses: Learning What (not) to Forget [<a href="https://arxiv.org/pdf/1711.09601.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Feb. 26 </td>
                                                       <td> <br> Suhail <br> Siddhesh </td>
                                                       <td> <b> Generative Models </b> <br> Probabilistic Neural Programmed Networks for Scene Generation [<a href="https://papers.nips.cc/paper/7658-probabilistic-neural-programmed-networks-for-scene-generation.pdf">link</a>] <br> Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects [<a href="https://arxiv.org/pdf/1806.01794.pdf">link</a>] </td>
                                                     </tr>
						     
						     <tr>
                                                       <td> Feb. 5 </td>
                                                       <td> Alireza </td>
                                                       <td> Neural Ordinary Differential Equations [<a href="https://arxiv.org/pdf/1806.07366.pdf">link</a>] </td>
                                                     </tr>

						     <tr>
                                                       <td> Jan. 15 </td>
                                                       <td> <br> Ariel <br> <br> Lixin </td>
                                                       <td> <b> Video Generative Models </b> <br> Video-to-video Synthesis [<a href="https://arxiv.org/abs/1808.06601">link</a>]  <br> <b> NN Optimization </b> <br> Group Normalization [<a href="https://arxiv.org/pdf/1803.08494.pdf">link</a>] </td>
                                                     </tr>

						</tbody>
                                        </table>
									-->

									<!--
                                        <h1>Finished presentations, 2018</h1>
                                        <table class="table table-striped table-condensed table-hover">
                                                <thead>
                                                        <tr>
                                                                <th class="col-md-2">Date</th>
                                                                <th class="col-md-2">Presenter</th>
                                                                <th>Paper or topic</th>
                                                        </tr>
                                                </thead>

                                                <tbody>

                                                    <tr>
                                                       <td> Nov. 22 </td>
                                                       <td> <br> Jim <br> <br> Polina </td>
                                                       <td> <b> Unsupervised GANs </b> <br> Dense Pose Transfer [<a href="https://arxiv.org/pdf/1809.01995.pdf">link</a>] <br> <b> Video Generative Models </b> <br> Everybody Dance Now [<a href="https://arxiv.org/pdf/1808.07371.pdf">link</a>] </td>
                                                    </tr>

						    <tr>
                                                       <td> Nov. 8 </td>
                                                       <td> <br> Yuan <br> Weidong </td>
                                                       <td> <b> Unsupervised GANs </b> <br> Diverse Image-to-Image Translation via Disentangled Representations [<a href="https://arxiv.org/pdf/1808.00948.pdf">link</a>] <br> GANimation: Anatomically-aware Facial Animation from a Single Image [<a href="https://arxiv.org/abs/1807.09251">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                       <td> Nov. 1 </td>
                                                       <td> <br> Borna </td>
                                                       <td> <b> Auto-Encoders </b>  <br> Adversarial Autoencoders [<a href="https://arxiv.org/pdf/1511.05644.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                       <td> Oct. 25 </td>
                                                       <td> <br> Siddhesh <br> Setareh </td>
                                                       <td> <b> Reasoning with Interpretability </b> <br> Explainable Neural Computation via Stack Neural Module Networks [<a href="https://arxiv.org/pdf/1807.08556.pdf">link</a>] <br> Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning [<a href="https://arxiv.org/pdf/1803.05268.pdf">link</a>] </td>
                                                    </tr>
                                                    
                                                    <tr>
                                                       <td> Oct. 18 </td>
                                                       <td> <br> Leon </td>
                                                       <td> <b> Overview of Bias in NN </b> <br> Relational Inductive Biases, Deep Learning, and Graph Networks [<a href="https://arxiv.org/pdf/1806.01261.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                       <td> Oct. 11 </td>
                                                       <td> <br> Hooman <br> Suhail </td>
                                                       <td> <b> Scene Understanding &amp; Reasoning </b> <br> Compositional Neural Networks for Machine Reasoning [<a href="https://arxiv.org/pdf/1803.03067.pdf">link</a>] <br> Iterative Visual Reasoning Beyond Convolution [<a href="https://arxiv.org/abs/1803.11189">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                       <td> Oct. 4 </td>
                                                       <td> <br> Mohit <br> Bicheng </td>
                                                       <td> <b> Scene Understanding &amp; Reasoning </b> <br> Detecting Objects by Transferring Common-sense Knowledge [<a href="https://arxiv.org/pdf/1804.01077.pdf">link</a>] <br> Graph R-CNN for Scene Graph Generation [<a href="https://arxiv.org/pdf/1808.00191.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Apr. 6 </td>
                                                    <td> Candice </td>
                                                    <td> What have we learned from deep representations for action recognition? [<a href="https://arxiv.org/pdf/1801.01415.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Mar. 23 </td>
                                                    <td> Gursimran </td>
                                                    <td> A Simple Neural Network Module for Relational Reasoning [<a href="https://arxiv.org/pdf/1706.01427.pdf">link</a>]</td>
                                                    </tr>

                                                    <tr>
                                                    <td> Mar. 2 </td>
                                                    <td> Polina </td>
                                                    <td> Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis [<a href="https://arxiv.org/pdf/1801.05091.pdf">link</a>]</td>
                                                    </tr>

                                                    <tr>
                                                    <td> Feb. 16 </td>
                                                    <td> Suhail </td>
                                                    <td> AttnGAN [<a href="https://arxiv.org/pdf/1711.10485.pdf">link</a>] <br> Generative Adversarial Text to Image Synthesis [<a href="https://arxiv.org/pdf/1605.05396.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Feb. 9 </td>
                                                    <td> Borna </td>
                                                    <td> Mask R-CNN [<a href="https://arxiv.org/pdf/1703.06870.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Feb. 2 </td>
                                                    <td> Bicheng </td>
                                                    <td> Teaching Machines to Describe Images via Natural Language Feedback [<a href="http://papers.nips.cc/paper/7092-teaching-machines-to-describe-images-with-natural-language-feedback.pdf">link</a>] </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Jan. 26 </td>
                                                    <td> Alireza </td>
                                                    <td> Is it hard to say I don't know? </td>
                                                    </tr>

                                                    <tr>
                                                    <td> Jan. 19 </td>
                                                    <td> Bo </td>
                                                    <td>Inferring and Executing Programs for Visual Reasoning [<a href="https://arxiv.org/pdf/1705.03633.pdf">link</a>]</td>
                                                    </tr>

                                                </tbody>
                                        </table>

									-->

					
					<!--
					<h1>Finished presentations, 2017</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>

						</thead>

						<tbody>
                            <tr>
                            <td> July 11, 2017 </td>
                            <td> Jianhui Chen </td>
                            <td> Shan Su etal. <em>Social Behavior Prediction from First Person Videos </em>, [<a href="https://arxiv.org/pdf/1611.09464.pdf">pdf</a>]</td>
                            </tr>
                            <tr>
                            <td> July 4, 2017 </td>
                            <td> Julieta Martinez </td>
                            <td> Meire Fortunato etal. <em>Noisy Networks for Exploration </em>, [<a href="https://arxiv.org/pdf/1706.10295.pdf">pdf</a>]</td>
                            </tr>
                            <tr>
                            <td> June 27, 2017 </td>
                            <td> Rayat Hossain </td>
                            <td> Kaiming He etal. <em>Mask R-CNN </em>, [<a href="https://arxiv.org/pdf/1703.06870.pdf">pdf</a>]</td>
                            </tr>
                            <tr>
                            <td> April 13, 2017 </td>
                            <td> Julieta Martinez </td>
                            <td> Rudy Bunel etal. <em>Learning to superoptimize programs </em>, [<a href="https://arxiv.org/pdf/1611.01787.pdf">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> April 7, 2017 </td>
                            <td> Jimmy Chen </td>
                            <td> Shenlong Wang etal. <em>The Global Patch Collider </em>, [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Wang_The_Global_Patch_CVPR_2016_paper.html">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> Match 10, 2017 </td>
                            <td> Jimmy Chen </td>
                            <td> Jimmy's thesis proposal</td>
                            </tr>

                            <tr>
                            <td> Match 3, 2017 </td>
                            <td> Vision group </td>
                            <td> Demos on Grad Visit Day</td>
                            </tr>

							<tr>
                            <td> February 24, 2017 </td>
                            <td> <a href="http://www.cs.ubc.ca/~leixiao/">Lei Xiao</a> </td>
                            <td> <em>Proximal Learning for Computational Imaging </em></td>
                            </tr>

							<tr>
                            <td> February 17, 2017 </td>
                            <td> Moumita Roy, Keyu Lu and Jimmy Chen </td>
                            <td> <em>A tutorial of <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="http://www.vlfeat.org/matconvnet/">MatConvNet</a> and <a href="http://caffe.berkeleyvision.org/">Caffe</a> </em></td>
                            </tr>

                            <tr>
                            <td> February 3, 2017 </td>
                            <td> Jimmy Chen </td>
                            <td> The-Anh Pham. <em>Pair-wisely optimized clustering tree for feature indexing </em>, [<a href="http://www.sciencedirect.com/science/article/pii/S1077314216301084">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> February 6, 2017 </td>
                            <td> <a href="http://www.cs.ubc.ca/~ftung/">Fred Tung</a> </td>
                            <td> <em>Fred's PhD thesis defense </em> </td>
                            </tr>

                            <tr>
                            <td> February 6, 2017 </td>
                            <td> <a href="http://www.cse.yorku.ca/~tsotsos/Tsotsos/Home.html">John K. Tsotsos</a> </td>
                            <td> <em>Attention is More Important for AI Than You Think </em> </td>
                            </tr>

                            <tr>
                            <td> January 20, 2017 </td>
                            <td> Julieta Martinez </td>
                            <td> Francesc Moreno-Noguer <em>3D Human Pose Estimation from a Single Image via Distance Matrix Regression</em>, unpublished [<a href="https://arxiv.org/pdf/1611.09010.pdf">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> January 13, 2017 </td>
                            <td> Jimmy Chen </td>
                            <td> Lakshminarayanan etal. <em>Mondrian Forests: Efficient Online Random Forests</em>, NIPS 2014 [<a href="https://papers.nips.cc/paper/5234-mondrian-forests-efficient-online-random-forests.pdf">pdf</a>]</td>
                            </tr>
						</tbody>
					</table>

				-->

				<!--
					<h1>Finished presentations, 2016</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>
						</thead>

						<tbody>


                            <tr>
                            <td> December 14, 2016 </td>
                            <td> Fred Tung </td>
                            <td> ACCV 2016 recap. [<a href="http://www.accv2016.org/">ACCV 2016</a>]</td>
                            </tr>

                            <tr>
                            <td> December 7, 2016 </td>
                            <td> Rayat Imtiaz </td>
                            <td> Bugar Tekin etal. <em>Structured Prediction of 3D Human Pose with Deep Neural Networks  </em>, BMVC 2016 [<a href="https://infoscience.epfl.ch/record/220616/files/tekin_bmvc16.pdf">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> November 23, 2016 </td>
                            <td> Moumita Roy </td>
                            <td> Vignesh Ramanathan etal. <em>Detecting events and key actors in multi-person videos  </em>, CVPR 2016 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Ramanathan_Detecting_Events_and_CVPR_2016_paper.pdf">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> November 14, 2016 </td>
                            <td> Fred Tung </td>
                            <td> Fred Tung and Jim Little: <em>SSP: Supervised Sparse Projections for large-scale retrieval in high dimensions </em>, ACCV 2016 [<a href="http://www.cs.ubc.ca/~ftung/papers/supervised_sparse_projections_accv16.pdf">pdf</a>]</td>
                            </tr>

                            <tr>
                            <td> October 26, 2016 </td>
                            <td> Jim Little</td>
                            <td> ECCV 2016 recap [<a href="http://www.eccv2016.org/">ECCV2016</a>]</td>
                            </tr>

                            <tr>
                            <td> October 5, 2016 </td>
                            <td> Fred Tung and Lili Meng</td>
                            <td> BMVC 2016 recap </td>
                            </tr>

						</tbody>

						<tbody>
                            <tr>
                            <td> September 28, 2016 </td>
                            <td> Jimmy Chen</td>
                            <td> Du Tran et al: <em>Learning Spatiotemporal Features with 3D Convolutional Networks </em>, ICCV 2015 [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Tran_Learning_Spatiotemporal_Features_ICCV_2015_paper.pdf">pdf</a>]</td>
                            </tr>

						</tbody>

						<tbody>
                            <tr>
                            <td> September 14, 2016 </td>
                            <td> Moumita Roy</td>
                            <td> Zhiwei Deng et al: <em>Structure Inference Machines: Recurrent Neural Networks for Analyzing Relations in Group Activity Recognition </em>, CVPR 2016 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Deng_Structure_Inference_Machines_CVPR_2016_paper.pdf">pdf</a>]</td>
                            </tr>

						</tbody>

						<tbody>
                                                        <tr>
                                                        <td> August 17, 2016 </td>
                                                        <td> Fred Tung </td>
                                                        <td> Fred Tung and Jim Little, <em>Factorized binary codes for large-scale nearest neighbor search </em>, to appear BMVC 2016 [<a href="http://www.cs.ubc.ca/~ftung/papers/factorized_binary_codes_bmvc16.pdf">pdf</a>]</td>
                                                        </tr>
                                                        <tr>
                                                            <td>August 10, 2016 </td>
                                                            <td>Rayat Imtiaz </td>
                                                            <td>Federica Bogo et al: <em>Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image</em>, from ECCV 16 [<a href="http://files.is.tue.mpg.de/black/papers/BogoECCV2016.pdf">pdf</a>]</td>
                                                        </tr>
							<tr>
								<td>August 3, 2016</td>
								<td>Micha Livne</td>
								<td>Performance capture</td>
							</tr>
							<tr>
								<td>July 20, 2016</td>
								<td>Ankur Gupta</td>
								<td>Ashesh Jain et al: <em>Structural-RNN: Deep Learning on Spatio-Temporal Graphs</em> [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Jain_Structural-RNN_Deep_Learning_CVPR_2016_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>July 13, 2016</td>
								<td>Many</td>
								<td><a href="https://www.cs.sfu.ca/~mori/">Greg Mori</a> and his students visited cvrg to talk about their ongoing and future research</td>
							</tr>
							<tr>
								<td>July 11, 2016</td>
								<td>Ankur Gupta, Jimmy Chen and Julieta Martinez</td>
								<td>A recap on CVPR 16</td>
							</tr>
							<tr>
								<td>July 6, 2016</td>
								<td>Julieta Martinez</td>
								<td>Relja Arandjelovic, Petr Gronat, Akihiko Torii, Tomas Pajdla, Josef Sivic <em>NetVLAD: CNN Architecture for Weakly Supervised Place Recognition</em>, from CVPR 16 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Arandjelovic_NetVLAD_CNN_Architecture_CVPR_2016_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>June 22, 2016</td>
								<td>Jimmy Chen</td>
								<td>Jianhui Chen, Hoang M. Le, Peter Carr, Yisong Yue, James J. Little <em>Learning Online Smooth Predictions for Realtime Camera Planning using Recurrent Decision Trees</em>, from CVPR 16 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Chen_Learning_Online_Smooth_CVPR_2016_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>June 21, 2016</td>
								<td><a href="http://www.cse.yorku.ca/~wildes/">Richard Wildes</a></td>
								<td>A Tale of Two Reference Frames</td>
							</tr>
							<tr>
								<td>June 15, 2016</td>
								<td>Ankur Gupta</td>
								<td>Ankur rehearsed his PhD thesis defense</td>
							</tr>
							<tr>
								<td>June 1, 2016</td>
								<td>Lili Meng</td>
								<td>Eric Brachmann, Frank Michel, Alexander Krull, Michael Ying Yang, Stefan Gumhold, and Carsten Rother <em>Uncertainty-Driven 6D Pose Estimation of Objects and Scenes from a Single RGB Image</em>, to appear at CVPR 2016 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Brachmann_Uncertainty-Driven_6D_Pose_CVPR_2016_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>May 10, 2016</td>
								<td>Moumita Roy</td>
								<td>Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu <em>Pixel Recurrent Neural Networks</em>, from ICML 2016 [<a href="https://arxiv.org/pdf/1601.06759v2.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>May 10, 2016</td>
								<td>Rayat Imtiaz</td>
								<td>Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, Kosta Derpanis, Kostas Daniilidis <em>Sparseness Meets Deepness: 3D Human Pose Estimation from Monocular Video</em>, to appear at CVPR 2016 [<a href="http://arxiv.org/pdf/1511.09439v2.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>May 4, 2016</td>
								<td>Julieta Martinez</td>
								<td>Deepak Pathak, Phillip Krähenbühl, Jeff Donahue, Trevor Darrell, Alexei A. Efros <em>Context Encoders: Feature Learning by Inpainting</em>, to appear at CVPR 2016 [<a href="http://people.eecs.berkeley.edu/~pathak/papers/cvpr16.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>April 20, 2016</td>
								<td>Julieta Martinez</td>
								<td>Kaiming He,  Xiangyu Zhang, Shaoqing Ren, Jifeng Dai, &amp; Jian Sun: <em>Deep residual learning for image recognition</em>, to appear at CVPR 2016 [<a href="http://arxiv.org/pdf/1512.03385v1.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>April 6, 2016</td>
								<td>Jimmy Chen</td>
								<td>Valentin et al.: <em>Exploiting Uncertainty in Regression Forests for Accurate Camera Relocalization</em>, from CVPR 2015 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Valentin_Exploiting_Uncertainty_in_2015_CVPR_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>March 23, 2016</td>
								<td>Fred Tung</td>
								<td>Shuran Song and Jianxiong Xiao: <em>Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images</em>, to appear at CVPR 2016 [<a href="http://vision.princeton.edu/projects/2015/DSS/paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>March 16, 2016</td>
								<td>Ankur Gupta</td>
								<td>A report trip from WACV 2016.</td>
							</tr>
							<tr>
								<td>February 9, 2016</td>
								<td>Ankur Gupta</td>
								<td>Katerina Fragkiadaki, Sergey Levine, Panna Felsen, Jitendra Malik: <em>Recurrent Network Models for Human Dynamics</em>, from ICCV 2015 [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Fragkiadaki_Recurrent_Network_Models_ICCV_2015_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>January 27, 2016</td>
								<td>Anahita Shojaei</td>
								<td>Limin Wang, Yu Qiao and Xiaoou Tang: <em>Action Recognition with Trajectory-Pooled Deep-Convolutional Descriptors</em>, from CVPR 2015 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wang_Action_Recognition_With_2015_CVPR_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>January 27, 2016</td>
								<td>Jimmy Chen</td>
								<td>Alex Kendall, Matthew Grimes and Roberto Cipolla: <em>PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization</em>, from ICCV 2015 [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>January 20, 2016</td>
								<td>Julieta Martinez</td>
								<td>Emily L. Denton, Soumith Chintala, Arthur Szlam, Rob Fergus: <em>Deep Generative Image Models using a ￼Laplacian Pyramid of Adversarial Networks</em>, from NIPS 2015 [<a href="http://papers.nips.cc/paper/5773-deep-generative-image-models-using-a-laplacian-pyramid-of-adversarial-networks.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>January 13, 2016</td>
								<td>Rayat Imtiaz</td>
								<td>Lawrence Zitnick and Devi Parikh: <em>Bringing Semantics into Focus using Visual Abstraction</em>, from CVPR 2013 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zitnick_Bringing_Semantics_into_2013_CVPR_paper.pdf">pdf</a>]</td>
							</tr>
						</tbody>
					</table>

				-->

				<!--

					<h1>Finished presentations, 2015</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>December 11, 2015</td>
								<td> -- </td>
								<td>We watched the CVPR 15 plenary talk by Yann LeCun: <em>What is wrong with deep learning? </em>[<a href="http://techtalks.tv/talks/whats-wrong-with-deep-learning/61639/">techtalk</a>].</td>
							</tr>
							<tr>
								<td>November 27, 2015</td>
								<td>Julieta Martinez</td>
								<td>Artem Babenko and Victor Lempitsky: <em>Aggregating deep convolutional features for image retrieval.</em>, from ICCV 2015 [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Babenko_Aggregating_Local_Deep_ICCV_2015_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>November 20, 2015</td>
								<td>Alireza Shafaei</td>
								<td>A tutorial / literature review on depth estimation from rgb.</td>
							</tr>
							<tr>
								<td>November 13, 2015</td>
								<td>Fred Tung</td>
								<td>Hang Su, Subhransu Maji, Evangelos Kalogerakis, and Erik Learned-Miller: <em>Multi-view convolutional neural networks for 3D shape recognition</em>, from ICCV 2015 [<a href="http://vis-www.cs.umass.edu/mvcnn/docs/su15mvcnn.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>October 30, 2015</td>
								<td>Joris Clement</td>
								<td><em></em>A talk on his research as an intern in the vision lab related to large-scale retrieval.</td>
							</tr>
							<tr>
								<td>October 19, 2015</td>
								<td>Alireza Shafaei</td>
								<td><em>Real-time Human Motion Capture with Depth Sensors</em>, as part of his MSc thesis presentation.</td>
							</tr>
							<tr>
								<td>October 16, 2015</td>
								<td>Jimmy Chen</td>
								<td><em>Camera Planning for Soccer Games</em>, as part of his RPE.</td>
							</tr>
							<tr>
								<td>October 9, 2015</td>
								<td>Kevin Woo</td>
								<td>Bogo F. et al.: <em>Detailed Full-Body Reconstructions of Moving People from Monocular RGB-D Sequences</em>, from ICCV 2015 [<a href="https://ps.is.tuebingen.mpg.de/publications/bogo-iccv-2015">html</a>].</td>
							</tr>
							<tr>
								<td>October 2, 2015</td>
								<td>Julieta Martinez</td>
								<td>Zheng S. et al.: <em>Conditional Random Fields as Recurrent Neural Networks</em>, from ICCV 2015 [<a href="http://www.robots.ox.ac.uk/~szheng/CRFasRNN.html">html</a>].</td>
							</tr>
							<tr>
								<td>September 24, 2015</td>
								<td><a href="http://www.ri.cmu.edu/people/ramanan_deva.html">Deva Ramanan</a></td>
								<td>Distinguished Lecture Series: <em>Understanding Visual Appearances in the Long-tail</em> [<a href="https://www.cs.ubc.ca/event/2015/09/understanding-visual-appearances-long-tail-dls-talk-deva-ramanan-cmu">html</a>][<a href="https://www.youtube.com/watch?v=YTHqXEI_vgs">youtube</a>].</td>
							</tr>
							<tr>
								<td>August 20, 27 &amp; Sept 3, 2015</td>
								<td>Various</td>
								<td>We are attending the seminar on <em>probabilistic graphical models</em> organized by the <a href="http://www.cs.ubc.ca/~issamou/mlrg.html">machine learning reading group</a>.</td>
							</tr>
							<tr>
								<td>August 15, 2015</td>
								<td>Fred Tung</td>
								<td>A. Gonzalez-Garcia, A. Vezhnevets, V. Ferrari. <em>An active search strategy for efficient object class detection</em>, from CVPR 2015 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/presentations/Gonzalez-Garcia_An_Active_Search_2015_CVPR_paper.pdf">pdf</a>].</td>
							</tr>
							<tr>
								<td>August 6, 2015</td>
								<td>John He</td>
								<td><em>Retrieval of human motion with flexible alignment.</em></td>
							</tr>
							<tr>
								<td>July 30, 2015</td>
								<td>Julieta Martinez</td>
								<td>A whirlwind tour on vector compression for large-scale computer vision applications.</td>
							</tr>
							<tr>
								<td>July 23, 2015</td>
								<td><a href="http://ai.stanford.edu/~olga/">Olga Russakovsky</a></td>
								<td><em>Scaling up Object Detection.</em></td>
							</tr>
							<tr>
								<td>July 16, 2015</td>
								<td>Lili Meng</td>
								<td>Richard A. Newcombe, Steven J. Lovegrove and Andrew J. Davison. <em>DTAM: Dense Tracking and Mapping in Real-Time</em>, from ICCV 2011. [<a href="http://homes.cs.washington.edu/~newcombe/papers/newcombe_etal_iccv2011.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>July 9, 2015</td>
								<td>Jimmy Chen</td>
								<td>Guzmán-Rivera et al. <em>Multi-Output Learning for Camera Relocalization</em>, from CVPR 14 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Guzman-Rivera_Multi-Output_Learning_for_2014_CVPR_paper.pdf">pdf</a>]</td>
							</tr>
							<tr>
								<td>July 2, 2015</td>
								<td>Alireza Shafaei</td>
								<td>Ho Yub Jung, Soochahn Lee, Yong Seok Heo and Il Dong Yun. <em>Random Tree Walk toward Instantaneous 3D Human Pose Estimation</em>, from CVPR 15. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Jung_Random_Tree_Walk_2015_CVPR_paper.pdf">pdf</a>]</td></tr>
							<tr>
								<td>June 25, 2015</td>
								<td>Julieta Martinez</td>
								<td>Ijaz Akhter and Michael J. Black. <em>Pose-Conditioned Joint Angle Limits for 3D Human Pose Reconstruction</em>, from CVPR 2015. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Akhter_Pose-Conditioned_Joint_Angle_2015_CVPR_paper.pdf">pdf</a>]</td></tr>
							<tr>
								<td>June 18, 2015</td>
								<td>Jim Little</td>
								<td>A report on his trip to <a href="http://www.pamitc.org/cvpr15/">CVPR 2015</a>.</td></tr>
							<tr>
								<td>June 4, 2015</td>
								<td>Ankur Gupta</td>
								<td>Meyer et al. <em>Phase-Based Frame Interpolation for Video</em>, from CVPR 2015 [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Meyer_Phase-Based_Frame_Interpolation_2015_CVPR_paper.pdf">pdf</a>]</td></tr>
							<tr>
								<td>March 20, 2015</td>
								<td>Fred Tung</td>
								<td>Abhijit Kundu, Yin Li, Frank Daellert, Fuxin Li and James M. Rehg. <em>Joint Semantic Segmentation and 3D Reconstruction from Monocular Video</em>, from ECCV 2014. [<a href="http://www.cc.gatech.edu/~dellaert/pubs/Kundu14eccv.pdf">pdf</a>]</td></tr>
							<tr>
								<td>March 13, 2015</td>
								<td>Ankur Gupta</td>
								<td>Matthew M. Loper and Michael J. Black. <em>OpenDR: An Approximate Differentiable Renderer</em>, from ECCV 2014. [<a href="http://files.is.tue.mpg.de/black/papers/OpenDR.pdf">pdf</a>] </td></tr>
							<tr>
								<td>February 27, 2015</td>
								<td>Julieta Martinez</td>
								<td>Katerina Fragkiadaki, Marta Salas, Pablo Arbelaez and Jitendra Malik. <em>Grouping-Based Low-Rank Trajectory Completion and 3D Reconstruction</em>, from NIPS 2014. [<a href="http://papers.nips.cc/paper/5414-grouping-based-low-rank-trajectory-completion-and-3d-reconstruction.pdf">pdf</a>] </td></tr>
							<tr>
								<td>February 13, 2015</td>
								<td>Jimmy Chen</td>
								<td>Dubská, M., Sochor, J., &amp; Herout, A. <em>Automatic Camera Calibration for Traffic Understanding</em>, from BMVC 2014 [<a href="http://www.bmva.org/bmvc/2014/files/paper013.pdf">pdf</a>].</td></tr>
							<tr>
								<td>February 6, 2015</td>
								<td>Victor Gan</td>
								<td>Rodrigo Benenson, Mohamed Omran, Jan Hosang and Bernt Schiele. <em>Ten Years of Pedestrian Detection, What Have We Learned?</em> posted to arxiv on November last year [<a href="http://arxiv.org/pdf/1411.4304.pdf">pdf</a>].</td></tr>
							<tr>
								<td>January 30, 2015</td><td>Ankur Gupta</td>
								<td>Mohsen Hejrati and Deva Ramanan. <em>Analysis by Synthesis: 3D Object Recognition by Object Reconstruction</em>, from CVPR 2014. [<a href="http://www.ics.uci.edu/~shejrati/files/2014CVPR_AnalysisBySynthesis.pdf">pdf</a>]</td></tr>
							<tr>
								<td>January 23, 2015</td><td>Alireza Shafaei</td>
								<td>Andrej Karpathy and Fei-Fei Li. <em>Deep visual-semantic alignments for generating image descriptions</em>. arXiv preprint arXiv:1412.2306 (2014). [<a href="http://arxiv.org/abs/1412.2306">arxiv</a>]</td></tr>
							<tr>
								<td>January 16, 2015</td>
								<td>Jimmy Chen &amp; Fred Tung</td>
								<td>A recap on <a href="http://wacv2015.org/">WACV 15</a>.</td></tr>
						</tbody>
					</table>

				-->

				<!--

					<h1>Finished presentations, 2014</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Nov 20, 2014</td>
								<td>Julieta Martinez</td>
								<td>Pickup, L.C., Pan, Z., Wei, D., Shih, Y., Zhang, C., Zisserman, A., Schölkopf, B. and Freeman, W.T. <em>Seeing the Arrow of Time</em>. [<a href="http://www.robots.ox.ac.uk/~vgg/publications/2014/Pickup14/pickup14.pdf">pdf</a>]</td></tr>
							<tr>
								<td>Oct 30, 2014</td>
								<td>Alireza Shafaei</td>
								<td>Kevin Matzen and Noah Snavely. <em>Scene Chronology</em>, from ECCV 2014 [<a href="http://www.cs.cornell.edu/~snavely/publications/matzen_eccv2014.pdf">pdf</a>] </td></tr>
							<tr>
								<td>Oct 23, 2014</td>
								<td>Jimmy Chen</td>
								<td>Sean Ryan Fanello, Cem Keskin, Pushmeet Kohli, Shahram Izadi, Jamie Shotton, Antonio Criminisi, Ugo Pattacini, Tim Paek. <em>Learning Data-Dependent Convolutional Kernels</em>, from CVPR 2014 [<a href="http://research.microsoft.com/pubs/217099/CVPR2014ForestFiltering.pdf">pdf</a>]</td></tr>
							<tr>
								<td>Oct 16, 2014</td>
								<td>Victor Gan</td>
								<td>Laurens van der Maaten. <em>Barnes-Hut-SNE</em>, from ICLR 2013 [<a href="http://arxiv.org/pdf/1301.3342v2.pdf">pdf</a>].</td></tr>
							<tr>
								<td>Oct 8, 2014</td>
								<td>Alireza Shafaei</td>
								<td>Ross Girshick, Forrest Iandola, Trevor Darrell and Jitendra Malik. <em>Deformable Part Models are Convolutional Neural Networks</em>, from Arxiv a few weeks ago [<a href="http://arxiv.org/pdf/1409.5403v2.pdf">pdf</a>].</td></tr>
							<tr>
								<td>Oct 1, 2014</td>
								<td>Julieta Martinez</td>
								<td>Shiry Ginosar, Daniel Haas, Timothy Brown, and Jitendra Malik. <em>Detecting People in Cubist Art</em>. [<a href="http://arxiv.org/pdf/1409.6235.pdf">arxiv</a>], and Crowley, E. J., Zisserman, A. <em>The State of the Art: Object Retrieval in Paintings using Discriminative Regions</em> [<a href="http://www.robots.ox.ac.uk:5000/~vgg/publications/2014/Crowley14/crowley14.pdf">pdf</a>] from BMVC 2014.</td></tr>
							<tr>
								<td>Sept 24, 2014</td>
								<td>Fred Tung</td>
								<td>A trip report on <a href="http://eccv2014.org/">ECCV 2014</a>.</td>
								</tr>
								<tr>
									<td>Sept 17, 2014</td>
									<td>Alireza Shafaei</td>
									<td>Jia Deng, Nan Ding, Yangqing Jia, Andrea Frome, Kevin Murphy, Samy Bengio, Yuan Li, Hartmut Neven, Hartwig Adam. <em>Large-Scale Object Classification using Label Relation Graphs</em>, from ECCV 2014. [<a href="http://www.cs.ubc.ca/~murphyk/Papers/eccv2014.pdf">external link</a>].</td></tr>
								<tr>
									<td>July 22, 2014</td>
									<td>Ankur Gupta</td><td>Chun-Hao Huang, Edmond Boyer, Nassir Navab, Slobodan Ilic, <em>Human Shape and Pose Tracking Using Keyframes</em>, CVPR 2014. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Huang_Human_Shape_and_2014_CVPR_paper.pdf">external link</a>].</td></tr>
								<tr>
									<td>July 15, 2014</td>
									<td>Alireza Shafaei</td><td>Jonathan Tompson, Arjun Jain, Yann LeCun, Christoph Bregler, <em>Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation</em>, ArXiv preprint.[<a href="http://arxiv.org/abs/1406.2984">external link</a>].</td></tr>
								<tr>
									<td>June 10, 2014</td>
									<td>Neil Traft</td><td>Henriques, J. F., Caseiro, R., Martins, P., &amp; Batista, J, <em>Exploiting the circulant structure of tracking-by-detection with kernels</em>, ECCV 2012. [<a href="http://home.isr.uc.pt/~henriques/publications/henriques_eccv2012.pdf">external link</a>].</td></tr>
								<tr>
									<td>May 27, 2014</td>
									<td>Alireza Shafaei</td>
									<td>Hamed Pirsiavash, Deva Ramanan, <em>Parsing videos of actions with segmental grammars</em>, CVPR 2014. [<a href="http://people.csail.mit.edu/hpirsiav/papers/grammar_cvpr14.pdf">external link</a>].</td>
								</tr>
								<tr>
									<td>May 20, 2014</td>
									<td>Ankur Gupta</td>
									<td>Andreas Lehrmann, Peter Gehler, Sebastian Nowozin, <em>Efficient Nonlinear Markov Models for Human Motion</em>, CVPR 2014. [<a href="http://www.nowozin.net/sebastian/papers/lehrmann2014nonlinearmarkov.pdf">external link</a>].</td>
								</tr>
								<tr>
									<td>May 12, 2014</td>
									<td>Alireza Shafaei</td>
									<td>Anoop Cherian, Julien Mairal, Karteek Alahari, Cordelia Schmid, <em>Mixing Body-Part Sequences for Human Pose Estimation</em>, CVPR 2014. [<a href="http://hal.inria.fr/docs/00/97/86/43/PDF/posecvpr2014.pdf">external link</a>].</td></tr>
								<tr>
									<td>April 28, 2014</td>
									<td>Julieta Martinez</td>
									<td>Mohammad Norouzi Ali Punjani David J. Fleet, <em>Fast Search in Hamming Space with Multi-Index Hashing</em>, CVPR 2012. [<a href="http://www.cs.toronto.edu/~norouzi/research/papers/multi_index_hashing.pdf">external link</a>].</td></tr>
								<tr>
									<td>April 10, 2014</td>
									<td>Ankur Gupta</td><td>Ryan Tokola, Wongun Choi, Silvio Savarese, <em>Breaking the chain: liberation from the temporal Markov assumption for tracking human poses</em>, ICCV 2013. [<a href="http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Tokola_Breaking_the_Chain_2013_ICCV_paper.pdf">external link</a>].</td></tr>
								<tr>
									<td>March 24, 2014</td>
									<td>Ankur Gupta</td><td>Andreas Lehrmann, Peter V. Gehler, Sebastian Nowozin, <em>A Non-parametric Bayesian Network Prior of Human Pose</em>, ICCV 2013. [<a href="http://www.nowozin.net/sebastian/papers/lehrmann2013humanposeprior.pdf">external link</a>].</td></tr>
								<tr>
									<td>March 17, 2014</td>
									<td>Julieta Martinez</td><td>R Urtasun, T Darrell. <em>Sparse probabilistic regression for activity-independent human pose inference. CVPR 2008</em>. [<a href="http://mplab.ucsd.edu/wp-content/uploads/CVPR2008/Conference/data/papers/020.pdf">external link</a>].</td></tr>
								<tr>
									<td>Feb 03, 2014</td>
									<td>Julieta Martinez</td><td>E. Simo-Serra, A. Quattoni, C. Torras, and F. Moreno-Noguer. <em>A Joint Model for 2D and 3D Pose Estimation from a Single Image</em>. CVPR '13. [<a href="http://www.iri.upc.edu/people/esimo/publications/SimoSerraCVPR2013.pdf">external link</a>].</td></tr>
								<tr>
									<td>Jan 27, 2014</td>
									<td><a href="http://www.cs.ubc.ca/~little/">Jim Little</a></td><td>Xinchao Wang, Vitaly Ablavsky, Horesh Ben Shitrit, and Pascal Fua. <em>Take your Eyes off the Ball: Improving Ball-Tracking by Focusing on Team Play</em> Computer Vision and Image Understanding (CVIU), Vol. 119, 2014. [<a href="http://cvlabwww.epfl.ch/~ablavsky/publications/fos-cviu2013.pdf">external link</a>].</td></tr>
								<tr>
									<td>Jan 20, 2014</td>
									<td>Ankur Gupta</td><td>Dicle, C., Sznaier, M., &amp; Camps, O. <em>The Way They Move: Tracking Multiple Targets with Similar Appearance</em>, from ICCV 2013. [<a href="http://www.coe.neu.edu/~cdicle/papers/dicle_iccv13.pdf">external link</a>].</td></tr>
						</tbody>
					</table>

				-->

				<!--

					<h1>Finished presentations, 2013</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Dec 06, 2013</td>
								<td>Fred Tung</td><td>Guangnan Yey, Dong Liuy, Jun Wangz, and Shih-Fu Changy. Large Scale Video Hashing via Structure Learning. ICCV'13. [<a href="http://www.ee.columbia.edu/ln/dvmm/publications/13/Large-ScaleVideoHashingviaStructureLearning.pdf">external link</a>].</td></tr>
							<tr>
								<td>Nov 29, 2013</td>
								<td>Ankur Gupta</td><td>Hueihan Jhuang, Juergen Gall, Silvia Zuffi, Cordelia Schmid, and Michael J. Black. Towards understanding action recognition. ICCV'13. [<a href="http://files.is.tue.mpg.de/black/papers/JHMDB_ICCV_2013.pdf">external link</a>].</td></tr>
							<tr>
								<td>Nov 22, 2013</td>
								<td>Julieta Martinez</td><td>Matthijs Douze, Jerome Revaud, Cordelia Schmid and Herve Jegou. Stable hyper-pooling and query expansion for event detection. ICCV'13. [<a href="http://hal.inria.fr/docs/00/87/27/51/PDF/douze_iccv13.pdf">external link</a>].</td></tr>
							<tr>
								<td>Nov 15, 2013</td>
								<td>Anil Mahmud</td><td>Alldrin, N.G. and Kriegman, D. Toward Reconstructing Surfaces With Arbitrary Isotropic Reflectance : A Stratified Photometric Stereo Approach. ICCV'07. [<a href="http://www.cs.virginia.edu/~mjh7v/bib/Alldrin07.pdf">external link</a>].</td></tr>
							<tr>
								<td>Nov 08, 2013</td>
								<td>Georgii Oleinikov</td><td>Ben Sapp and Ben Taskar. MODEC: Multimodal Decomposable Models for Human Pose Estimation. CVPR'13. [<a href="http://www.seas.upenn.edu/~bensapp/cvpr13-modec.pdf">external link</a>].</td></tr>
							<tr>
								<td>Oct 18, 2013</td>
								<td>Julieta Martinez</td><td>Herve Jegou, Ondrej Chum. Negative evidences and co-occurrences in image retrieval: the benefit of PCA and whitening. ECCV'12. [<a href="http://hal.archives-ouvertes.fr/docs/00/72/26/26/PDF/jegou_chum_eccv2012.pdf">external link</a>].</td></tr>
							<tr>
								<td>Oct 11, 2013</td>
								<td>Anil Mahmud</td><td>Thoma Papadhimitri and Paolo Favaro. A New Perspective on Uncalibrated Photometric Stereo. CVPR'13. [<a href="http://www.cvg.unibe.ch/publications/papadhimitri2013new.pdf">external link</a>]. Additional reading: Photometric stereo under a light source with arbitrary  motion [<a href="http://www.opticsinfobase.org/josaa/abstract.cfm?uri=josaa-11-11-3079">link</a>], Photometric stereo under perspective projection [<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1541310&amp;tag=1">link</a>]. </td></tr>
							<tr>
								<td>Sept 27, 2013</td>
								<td>Ankur Gupta</td><td>Zhang, Z., Wang, C., Xiao, B., Zhou, W., Liu, S., &amp; Shi, C. Cross-View Action Recognition via a Continuous Virtual Path. CVPR'13. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Zhang_Cross-View_Action_Recognition_2013_CVPR_paper.pdf">external link</a>]</td></tr>
							<tr>
								<td>Sept 13, 2013</td>
								<td>Julieta Martinez</td><td>Jrme Revaud, Matthijs Douze, Cordelia Schmid, Herv Jgou. Event Retrieval in Large Video Collections with Circulant Temporal Encoding. CVPR'13. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Revaud_Event_Retrieval_in_2013_CVPR_paper.pdf">external link</a>]</td></tr>
							<tr>
								<td>July 25, 2013</td>
								<td>Julieta Martinez</td><td>Fragkiadaki F., Hu H. and Shi J. Pose from Flow and Flow from Pose. CVPR'13. [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Fragkiadaki_Pose_from_Flow_2013_CVPR_paper.pdf">external link</a>]</td></tr>
							<tr>
								<td>July 18, 2013</td>
								<td>Georgii Oleinikov</td><td>Yicong Tian, Rahul Sukthankar, Mubarak Shah. Spatiotemporal Deformable Part Models for Action Detection, Computer Vision and Pattern Recognition (CVPR), Portland, Oregan, June 2013. [<a href="http://www.cs.ucf.edu/~ytian/cvpr2013-sdpm.pdf">external link</a>]</td></tr>
							<tr>
								<td>June 20, 2013</td>
								<td>Georgii Oleinikov</td><td>L. Ladický, P.H.S. Torr, A. Zisserman. Human Pose Estimation using a Joint Pixel-wise and Part-wise Formulation. To appear at CVPR 2013. [<a href="http://www.inf.ethz.ch/personal/ladickyl/pose_cvpr13.pdf">external link</a>]</td></tr>
							<tr>
								<td>June 13, 2013</td>
								<td>Julieta Martinez</td><td>Arpit Jain, Abhinav Gupta, Mikel Rodriguez, Larry S. Davis Representing Videos using Mid-level Discriminative Patches. To appear at CVPR 2013. [<a href="http://www.cs.cmu.edu/~abhinavg/papers/videos_13.pdf">external link</a>]</td></tr>
							<tr>
								<td>June 06, 2013</td>
								<td>Ankur Gupta</td><td>Chao-Yeh Chen and Kristen Grauman. Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots. To appear at CVPR 2013. [<a href="http://www.cs.utexas.edu/~grauman/papers/chen-grauman-cvpr2013.pdf">external link</a>]</td></tr>
							<tr>
								<td>April 05, 2013</td>
								<td>Ankur Gupta</td><td>Raptis, M., Kokkinos, I., &amp; Soatto, S. (2012). Discovering discriminative action parts from mid-level video representations. Presented at CVPR 2012. [<a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=6247807&amp;contentType=Conference+Publications&amp;searchField=Search_All&amp;queryText=Discovering+discriminative+action+parts+from+mid-level+action+representation">external link</a>]</td></tr>
							<tr>
								<td>March 15, 2013</td>
								<td>Bob Woodham</td><td>Hao-Yu Wu, Michael Rubinstein, Eugene Shih, John Guttag, Frédo Durand,&amp; William T. Eulerian Video Magnification for Revealing Subtle Changes in the World. Presented at SIGGRAPH 2012. [<a href="http://people.csail.mit.edu/mrub/papers/vidmag.pdf">external link</a>]</td></tr>
							<tr>
								<td>March 08, 2013</td>
								<td>Julieta Martinez</td><td>Henriques, J. F., Caseiro, R., Martins, P., &amp; Batista, J. Exploiting the Circulant Structure of Tracking-by-detection with Kernels. Presented at ECCV 2012. [<a href="http://www2.isr.uc.pt/~henriques/publications/henriques_eccv2012.pdf">external link</a>]</td></tr>
							<tr>
								<td>Feb 08, 2013</td>
								<td>Georgii Oleinikov</td><td>Camps, O. I., &amp; Sznaier, M. <em>Cross-view activity recognition using Hankelets</em>. IEEE Conference on Computer Vision and Pattern Recognition, 1362-1369, 2012. [<a href="http://www.cs.huji.ac.il/~peleg/CVPR2012/data/papers/172_P2A-22.pdf">external link</a>]</td></tr>
							<tr>
								<td>Feb 01, 2013</td>
								<td><a href="http://www.cs.ubc.ca/~little/">Jim Little</a></td><td>Vincent Delaitre, David F. Fouhey, Ivan Laptev, Josef Sivic, Abhinav Gupta, Alexei Efros. Scene semantics from long-term observation of people. In Proc. 12th European Conference on Computer Vision. 2012. [<a href="http://www.di.ens.fr/willow/pdfscurrent/delaitre_ECCV12.pdf">external link</a>]</td></tr>
							<tr>
								<td>Jan 18, 2013</td>
								<td>Georgii Oleinikov</td><td>H. Jhuang, T. Serre, L. Wolf, and T. Poggio. A biologically inspired system for
									action recognition. ICCV, pp. 1-8, 2007 [<a href="http://www.cnbc.cmu.edu/cns/papers/Jhuang_etal_iccv07.pdf">external link</a>]</td></tr>
							<tr>
								<td>Jan 11, 2013</td>
								<td>David Matheson</td><td>Christian Leistner, Martin Godec, Samuel Schulter, Amir Saffari,
									Manuel Werlberger, and Horst Bischof <em>Improving Classifiers with Unlabeled Weakly-Related Videos </em>
									In Proc. IEEE Conf. on Computer Vision and Pattern Recognition, 2011 [<a href="http://lrs.icg.tugraz.at/pubs/leistner_cvpr_11.pdf">external link</a>]</td></tr>

						</tbody>
					</table>

				-->

				<!--

					<h1>Finished presentations, 2012</h1>
					<table class="table table-striped table-condensed table-hover">
						<thead>
							<tr>
								<th class="col-md-2">Date</th>
								<th class="col-md-2">Presenter</th>
								<th>Paper or topic</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Dec 10, 2012</td>
								<td><a href="http://www.cs.ubc.ca/~junaed/">Junaed Sattar</a></td><td>François Fleuret, Jérôme Berclaz, Richard Lengagne, Pascal Fua. <em>Multicamera People Tracking with a Probabilistic Occupancy Map</em>, PAMI, 2008. [<a href="http://cvlab.epfl.ch/publications/publications/2008/FleuretBLF08.pdf">paper link</a>]</td></tr>
							<tr>
								<td>Dec 03, 2012</td>
								<td><a href="http://www.cs.ubc.ca/~ankgupta/">Ankur Gupta</a></td><td>O. Kliper-Gross, Y. Gurovich, T. Hassner, and L. Wolf, <em>Motion Interchange Patterns for Action Recognition in Unconstrained Videos</em>, European Conference on Computer Vision (ECCV), Firenze, Italy, Oct 2012 [<a href="http://www.openu.ac.il/home/hassner/projects/MIP/">external link</a>]</td></tr>
							<tr>
								<td>Nov 26, 2012</td>
								<td><a href="http://www.cs.ubc.ca/~little/">Jim Little</a></td><td>Wongun Choi and Silvio Savarese, <em> A Unified Framework for Multi-Target Tracking and Collective Activity Recognition</em>, ECCV'12. [<a href="http://www-personal.umich.edu/~wgchoi/eccv12/wongun_eccv12.html">external link</a>]</td></tr>
							<tr>
								<td>Nov 19, 2012</td>
								<td>Masaki Takahasi</td><td>Bo Yang and Ram Nevatia, <em> An Online Learned CRF Model for Multi-Target Tracking</em>. In Proceedings of IEEE Computer Vision and Pattern Recognition (CVPR), Providence, USA, Jun. 2012 [<a href="http://iris.usc.edu/people/yangbo/papers/CVPR12_2.pdf">Paper link</a>]</td></tr>
							<tr>
								<td>Nov 5, 2012</td>
								<td><a href="http://www.cs.ubc.ca/~ankgupta/">Ankur Gupta</a></td><td>Kevin Karsch, Ce Liu, Sing Bing Kang, <em> Depth Extraction from Video Using Non-parametric Sampling</em>, ECCV'12. [<a href="http://www.kevinkarsch.com/depthtransfer/">external link</a>]</td></tr>
							<tr>
								<td>Oct 29, 2012</td>
								<td>David Matheson</td><td>Z. Kalal, J. Matas, and K. Mikolajczyk, <em>P-N learning: Bootstrapping binary classifiers by structural constraints</em>, Conference on Computer Vision and Pattern Recognition, 2010. [<a href="http://info.ee.surrey.ac.uk/Personal/Z.Kalal/tld.html">external link</a>]</td></tr>
							<tr>
								<td>Oct 22, 2012</td>
								<td>Masaki Takahasi</td><td>Hervé Jégou, Matthijs Douze, Cordelia Schmid, Patrick Pérez, <em> Aggregating local descriptors into a compact image representation</em>, IEEE Conference on Computer Vision &amp; Pattern Recognition, 2010.[<a href="http://lear.inrialpes.fr/pubs/2010/JDSP10/">external link</a>] </td></tr>

						</tbody>
					</table>

				-->
				</div>
			</div>
		</div>
	

</body></html>